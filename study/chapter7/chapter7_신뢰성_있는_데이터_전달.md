# Chapter 7. 신뢰성 있는 데이터 전달

date: 2025년 7월 20일
status: Public
tags: Kafka
type: Post
updatedAt: 2025년 7월 29일 오후 10:56

카프카는 매우 세세한 지점까지 설정이 가능하여 신뢰성에 관한 모든 종류의 절충점이 가능하다?
-> yes silver bullet?

# 신뢰성 보장

표준 신뢰성 보장인 ACID

- 원자성
- 일관성
- 격리성
- 지속성

### 카프카가 제공하는 보장

- 파티션 안의 메시지들 간에 순서를 보장
- 클라이언트가 쓴 메시지는 모든 인-싱크 레플리카의 파티션에 쓰여진 뒤에 커밋된 것으로 간주한다 (디스크에 플러시될 필요 없음)
    - 프로듀서는 메시지가 완전히 커밋된 다음 응답이 올지, 리더에 쓰여진 다음 응답이 올지 네트워크로 전송된 다음 바로 응답이 올지 선택할 수 있다
- 커밋된 메시지는 최소 1개의 작동 가능한 레플리카가 남아 있는 한 유실되지 않는다
- 컨슈머는 커밋된 메시지만 읽을 수 있다

## 복제 매커니즘

파티션별로 다수의 레플리카를 유지한다는 특징이 있고 이는 카프카의 신뢰성 보장의 핵심이다

- 토픽은 파티션으로 이루어진다
- 하나의 파티션은 하나의 디스크에 저장된다
- 파티션에 저장된 이벤트들의 순서를 보장하고 파티션은 available, unavaliable 상태일 수 있다
- 각 파티션은 다수의 레플리카를 가질 수 있고 그 중 하나가 리더가 된다
- 모든 이벤트는 리더 레플리카에 쓰여지고 리더에서 읽혀진다
- 팔로워 레플리카는 단순히 리더와 동기화를 맞추고 최신 이벤트를 제 시간에 복사하기만 하면 된다
- 리더가 unavaliable 하면 인-싱크 레플리카 중 하나가 새 리더로 선출된다

### 인-싱크 상태란

- 주키퍼와의 활성 세션이 있다 주기적으로 주키퍼에 hert beat 를 전송
- 리더로부터 메시지를 일정 주기로 읽어온다
- 10초 사이에 리더로부터 읽거온 메시지들이 가장 최근 메시지이다
    - 팔로워가 리더로부터 메시지를 받는 것으로 부족하다
    - 최근 10초 사이에 lag이 없었던 적이 최소 한 번은 있어야 한다.

### 아웃-오브-싱크 레플리카

- 레플리카와 주키퍼 사이의 연결이 끊어지거나 새 메시지를 읽어오길 중단 하거나 10초 동안 업데이트 내역을 따라오지 못하는 경우

### 복제 지연

- 동기화가 살짝 늦은 인-싱크 레플리카는 프로듀서와 컨슈머를 느리게 할 수 있다
- 메시지가 커밋 되기 전에 모든 인-싱크 레플리카에 메시지가 복제되기 전까지 기다려야한다
- 동기화가 풀리면 더 이상 복제되기를 기다리지 않아도 되지만 메시지 유실 위험이 있다

# 브로커 설정

신뢰성 관련 설정은 3가지
이는 인프라 관리자 영역일것 같음

## 복제 팩터 replication.factor

- 토픽 단위 설정이다
- 자동으로 생성되는 토픽들에 적용되는 브로커 단위 설정은 default.replication.factor 설정에 잡는다

토픽의 복제 팩터가 3개로 가정
브로커가 3대의 서로 다른 브로커에 3개 복제되는 것을 의미

- 복제 팩터가 N이면 N-1개의 브로커가 중단되어도 토픽의 데이터를 읽거나 쓸 수 있다
- 복제 팩터가 크면 가용성과 신뢰성이 늘어나고 장애 발생 위험이 줄어든다
- 최소 N개의 브로커가 필요하고 N개의 복사본을 저장해야 해서 N배의 디스크 공간이 필요하다
- 가용성과 하드웨어의 trade off

토픽에 몇 개의 레플리카가 적절한지 알아보자

### 가용성

- 레플리카가 하나뿐인 파티션은 정기적으로 브로커를 재시작만 해도 unavailable 상태가 된다
- 레플리카가 늘어나면 가용성이 늘어난다

### 지속성

- 레플리카는 파티션 안의 모든 데이터의 복사본이다
- 레플리카가 하나일 때 디스크가 불능이 되면 모든 데이터는 유실 된다
- 복사본이 많을수록 데이터 유실 가능성이 줄어든다

### 처리량

- 레플리카가 추가될 때마다 브로커간 트래픽이 늘어난다
- 클러스터의 크기와 용량을 산정할 때 브로커의 부하를 생각해야 한다

### 종단 지연

- 쓰여진 메시지를 컨슈머가 읽으려면 모든 인-싱크 레플리카에 복제되어야 한다
- 레플리카 중 하나라도 느리게 복사된다면 컨슈머까지 느려진다
- 레플리카의 개수에 상관 없이 느리게 복사되는 만큼 컨슈머의 데이터 처리는 늦어진다

### 비용

- 레플리카가 늘어날수록 저장소와 네트워크 비용은 증가한다
- 복제 팩터를 2로 하면 3으로 할 때보다 비용은 줄어들지만 그만큼 가용성이 줄어든다
- 파티션의 모든 레플리카가 같은 랙에 설치되어 있다면 랙 스위치가 오작동 할 경우 복제 팩터와 상관 없이 파티션을 사용할 수 없다
- 랙 단위 사고를 방지하기 위해 브로커들을 서로 다른 랙에 배치한 후 broker.rack 브로커 설정에 랙 이름을 할당하는 것이 권장 됨
- 이름을 설정하면 파티션의 레플리카들이 서로 다른 랙에 분산되어 저장되도록 해서 가용성을 높임
- 클라우드에서 az를 나눠 사용하는 것과 유사한 개념

## 언클린 리더 선출 unclean.leader.election.enable = false

클러스터 단위에서만 가능하다  기본값은 false이다

unavailable한 리더 외에 인-싱크 레플리카가 없다면 ?
우선 발생 상황은 두 가지가 있다

### case 1

1. 파티션에 3개의 레플리카, 팔로워 2개가 unavailable
2. 리더에 쓰기 작업을 계속할 것이고 모든 메시지는 커밋 됨 (팔로워 2개가 불능이기 때문에 복제 x - 리더가 유일한 인-싱크 레플리카)
3. 브로커 크래시 발생으로 리더를 사용하지 못하는 상황 발생
4. 아웃-오브-싱크 레플리카 중 하나가 먼저 시작되면 파티션의 유일한 사용 가능 레플리카가 아웃-오브-싱크 레플리카가 된다

### case 2

1. 파티션에 3개의 레플리카가 있고 네트워크 문제로 팔로워 2개에 복제 지연 발생
2. 복제 작업은 진행중이지만 시간이 지나 더 이상 인-싱크 상태가 아님
3. 리더는 유일한 인-싱크로 메시지를 계속 받는다
4. 리더가 unavailable 되면 이제 리더가 될 레플리카는 아웃-오브-싱크 레플리카밖에 없다

### 해결하기

- 아웃-오브-싱크 상태가 새 리더가 될 수 없도록 하면 이전 리더가 복구될 때까지 해당 파티션은 오프라인 상태가 된다 복구까지 소요될 시간을 알 수 없다
- 아웃-오브-싱크 상태를 새 리더로 선출할 수 있게 하면 새 리더가 동기화를 못하는 사이 이전 리더에 쓰여진 모든 메시지는 유실되고 컨슈머 입장에서 일관성이 깨질 수 있다.
    - 레플리카 0과 1이 사용 불가능한 상태에서 레플리카 2가 작동 불능에 빠지고 0이 온라인이 된다. 0은 0~100 까지의 메시지를 가지고 있고 100~200 메시지는 없다.
    - 0이 새 리더가 될 수 있게 한다면 프로듀서들은 새 메시지를 0에 쓸 것이고 컨슈머 역시 0에서 읽어간다
    - 새 리더는 100~200에 해당하는 새 메시지를 가진다
    - 몇몇 컨슈머는 100~200에 해당하는 이전 메시지를 읽었겠지만, 일부는 같은 오프셋을 할당받은 새 메시지를 읽을 것이고 일부는 둘을 뒤섞인 채로 읽는다
    - "다운스트림 레포트"와 같은 경우 나쁜 상황이 발생한다
    - 만약 2가 복구되면 새 리더의 팔로워가 되고 이 시점에서 자신이 가지고 있는 메시지 중 현재 리더에 없는 메시지는 삭제할 것이다. 삭제된다면 이 메시지는 아무도 읽을 수 없다

아웃-오브-싱크 상태를 리더로 허용할 경우 데이터 유실과 일관성 문제가 발생한다
허용하지 않는다면 파티션이 온라인 상태가 될 때까지 기다려야 한다
unclean.leader.election.enable은 기본값으로 false이다

## 최소 인-싱크 레플리카 min.insync.replicas

- 토픽 당 3개의 레플리카를 설정해도 인-싱크 레플리카는 하나만 남을 수 있다
- 남은 하나의 레플리카가 불능이 될 경우 가용성과 일관성 사이에 하나를 골라야 한다
- 카프카가 보장하는 신뢰성은 "모든" 인-싱크 레플리카에 쓰여진 시점에서 커밋된 것으로 간주한다는 것이다
- 인-싱크가 하나만 남을 수도 있고, 이 남은 인-싱크가 불능이 될 수도 있다는 점이 있다
- 토픽에 레플리카가 3개가 있고 min.insync.replicas가 2이면 최소 2개의 인-싱크인 파티션에만 메시지를 쓸 수 있다
    - 두 개의 레플리카가 불능에 빠진다면 프로듀서는 메시지를 전송했을 때 NotEnoughReplicasException을 받는다
- 두 개의 사용 불능 레플리카 중 하나를 복구 시킨 뒤 리더 레플리카의 상태를 따라잡아서 인-싱크 상태로 들어갈 때까지 기다려야 한다

## 레플리카를 인-싱크 상태로 유지하기

zookeeper.session.timeout.ms
브로커가 주키퍼로 하트비트 전송을 멈출 수 있는 최대 시간
이 시간이 넘어가면 주키퍼는 브로커가 죽었다고 판단

replicas.lag.time.max.ms
이 값보다 더 오랫동안 리더로부터 데이터를 읽어오지 못하거나 리더에 쓰인 최신 메시지를 따라잡지 못하는 경우 동기화가 풀린 상태가 된다
회복 탄력성 증대와 불필요한 변동을 피하려고 2.5.0에서 30초로 지정됨

## 디스크에 저장하기  flush.messages, flush.ms

새그먼트를 교체할 때 재시작 직전에만 메시지를 디스크로 플러시하며 이외의 경우는 리눅스의 페이지 캐시 기능에 의존한다

- 리눅스 페이지 캐시 - 페이지 캐시 공간이 다 찼을 경우에만 메시지를 플러시 하는 것

서로 다른 랙이나 가용 영역에 위치한 세 대의 장비가 리더의 디스크에 메시지를 쓰는 것보다 더 안전하다는 판단
브로커가 디스크에 메시지를 더 자주 저장하도록 설정할 수는 있다
flush.messages 설정은 디스크에 저장되지 않은 최대 메시지 수를 flush.ms는 얼마나 자주 디스크에 메시지를 저장하는지 조절 할 수 있다

# 신뢰성 있는 시스템에서 프로듀서 사용하기

프로듀서 개발 시 고려할 사항은

- 신뢰성 요구 조건에 맞는 올바른 acks 설정을 사용한다
- 설정과 코드 모두에서 에러를 올바르게 처리한다

## 응답 보내기

### acks=0

- 메시지를 전송한 시점에 성공적으로 쓰여졌다고 간주한다
- 파티션이 오프라인이거나 리더를 선출 중이거나 전체 클러스터가 불능인 경우에도 성공적으로 쓰였다고 간주된다
- 지연은 낮지만 종단 지연이 개선되지 않는다 (컨슈머는 복제가 모두 되어야 메시지를 읽을 수 있다)

### acks=1

- 리더가 메시지를 받아서 파티션 데이터 파일에 쓴 직후 응답 또는 에러를 보낸다는 것을 의미
- 일부 메시지가 리더에 성공적으로 쓰여져서 클라이언트로 응답이 간 상태에서 팔로워로 복제가 완료되기 전에 리더가 정지되거나 크래시가 발생하면 데이터가 유실될 수 있다
- 메시지를 복제하는 속도보다 빠르게 리더에 쓰이게 되면 under-replicated partition(URP)가 발생한다
    - 리더 입장에서는 복제가 완료되기 전에 프로듀서에 응답을 하기 때문

### acks=all

- 리더가 모든 인-싱크 레플리카 메시지를 받아갈 때까지 기다렸다가 응답하거나 에러를 보내는 것
- 브로커의 min.insync.replicas 설정과 함께, 응답이 오기까지 얼마나 많은 레플리카에 복제할 것인지 조절할 수 있게 해준다
- 프로듀서는 메시지가 완전히 커밋될 때까지 계속해서 메시지를 재전송한다
- 프로듀서 지연이 길어지는 옵션이다

## 프로듀서 재시도 설정하기

재시도 가능한 에러와 재시도 불가능한 에러로 분류된다

`LEADER_NOT_AVAILABLE`: 재시도 가능 에러
`INVALID_CONFIG`: 재시도 불가

재시도 수를 기본 설정값 MAX_INT(무한) 으로 설정하고, 메시지 전송을 포기할 때까지 대기할 수 있는 시간을 지정하는 `delivery.timeout.ms` 설정을 최대로 잡아주는 것

재시도는 메시지 중복 위험을 가지고 있다
재시도와 주의 기은 메시지 처리는 "최소 한번"은 보장할 수 있지만, "정확히 한번"은 보장할 수 없다
`enable.idempotence=true` 설정으로 프로듀서가 추가적인 정보를 레코드에 포함할 수 있도록, 이를 활용해서 브로커가 재시도로 인해 중복된 메시지를 건너뛸 수 있도록 할 수 있다

## 추가적인 에러 처리

- 개발자 입장에서는 다른 종류의 에러를 처리할 수 있어야 한다
    - 메시지 크기에 관련되어 있거나 인가 관련 에러와 같이 재시도 불가능한 브로커 에러
    - 메시지가 브로커에 전송되기 전에 발생한 에러(직렬화 과정에서 발생한 에러)
    - 프로듀서가 모든 재전송 시도를 소진했거나, 재시도 과정에서 프로듀서가 사용하는 가용 메모리가 메시지로 가득 차서 발생하는 에러
    - 타임아웃

서비스에 따라 에러 처리가 달라질 수 있다 

# 신뢰성 있는 시스템에서 컨슈머 사용하기

데이터를 읽는 방법

- 컨슈머는 카프카에 커밋된 데이터만 읽을 수 있다
- 인-싱크 레플리카에 복제된 다음 처리할 수 있다
- 일관성이 보장되는 데이터만 읽는다
- 컨슈머는 배치 단위로 메시지를 읽어온다
- 오프셋 확인 후 다른 메시지 배치를 요청

## 신뢰성 있는 처리를 위한 컨슈머 설정

- `group.id` : 고유한 그룹 id를 가지는 컨슈머의 집합
- `auto.offset.reset`: 커밋된 오프셋이 없을 때나 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 해야할지 결정
    - earliest: 맨 앞에서부터 읽기
        - 중복 처리 가능성
    - latest: 끝부터 읽기
        - 일부 메시지 누락 가능성
- `enable.auto.commit` : 오프셋을 알아서 커밋할지 직접 커밋할지 결정
- `auto.commit.interval.ms` : 자동 커밋할 경우 커밋되는 주기 설정 가능
    - 5초 마다 커밋하는 것이 기본 설정
    - 커밋을 자주 할수록 브로커 오버헤드는 늘어나지만 정지했을 때 발생 가능한 중복은 줄어듦

### 컨슈머에서 명시적으로 오프셋 커밋하기

### 메시지 처리 먼저, 오프셋 커밋은 나중에

### 커밋 빈도는 성능과 크래시 발생시 중복 개수 사이의 트레이드 오프

- 커밋은 상당한 성능 오버헤드 발생
- 메시지를 읽을 때마다 커밋하는 경우는 낮은 빈도로 메시지가 들어오는 토픽에서 사용

### 정확한 시점에 정확한 오프셋을 커밋하자

- 처리가 완료된 메시지의 오프셋을 커밋하는 것이 좋다

### 리밸런스

- 파티션이 해제되기 전에 오프셋을 커밋하고, 새 파티션이 할당되었을 때 보유하고 있는 상태를 삭제해주는 작업을 포함

### 컨슈머는 재시도를 해야할 수도 있다

- 마지막으로 처리에 성공한 레코드의 오프셋을 커밋
- 나중에 처리할 레코드를 버퍼에 저장
- 컨슈머의 pause()를 호출해서 추가적인 poll 이 데이터를 리턴하지 않도록 하고 레코드를 처리
- 별도의 토픽에 쓴 뒤 진행
- dlq 시스템
- 재시도 토픽을 처리하는 중에는 주 토픽은 멈추기

### 컨슈머가 상태를 유지해야 할 수도 있다

- poll 메서드 호출 간에 상태를 유지해야 할 수도 있다
- 마지막으로 누적된 값을 오프셋 커밋할 때 results 토픽에 쓰는 것
- 작업이 중단된 시점과 마지막으로 누적된 값을 가져올 수 있다
- 스트림즈나 플링크 같은 집적 조인 등 복잡한 작업을 위한 고수준 dsl 형식 api 라이브러리 사용

# 시스템 신뢰성 검증하기

## 설정 검증하기

- 두 개의 중요한 툴을 포함
    - VerifiableProducer(검증용 프로듀서)
    - VerifiableConsumer(검증용 컨슈머)

명령줄 둘 형태로든 자동화된 테스팅 프레임워크에 포함되었든 실행이 가능

- 검증용 프로듀서를 실행하면 브로커에 전송된 각 메시지마다 성공이나 에러를 출력한다
- 컨슈머는 반대로 각 작업을 수행한다
- 커밋과 리밸런스 관련 정보를 출력된다

## 애플리케이션 검증하기

- 다양한 케이스를 테스트 하는 것이 좋음
- 가상의 네트워크나 디스크 장애를 발생시킬 수 있는 툴을 사용

## 프로덕션 환경에서 신뢰성 모니터링 하기

- 전체 데이터 흐름을 모니터링하는 것이 중요
- JMX 지표를 포함하고 있다
- 레코드별 에러율 , 재시도율
- 컨슈머 렉 지표 확인