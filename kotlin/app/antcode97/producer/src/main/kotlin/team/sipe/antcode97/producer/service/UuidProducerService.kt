package team.sipe.antcode97.producer.service

import org.slf4j.LoggerFactory
import org.springframework.kafka.core.KafkaTemplate
import org.springframework.kafka.support.SendResult
import org.springframework.stereotype.Service
import java.util.*
import java.util.concurrent.CompletableFuture
import java.util.concurrent.atomic.AtomicLong

/**
 * UUID ë©”ì‹œì§€ í”„ë¡œë“€ì„œ ì„œë¹„ìŠ¤
 * 
 * ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëŒ€ëŸ‰ ë©”ì‹œì§€ ë°œí–‰ê³¼ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í”„ë¡œë“€ì„œì…ë‹ˆë‹¤.
 * - ëŒ€ëŸ‰ ë©”ì‹œì§€ ë°œí–‰ (100ë§Œê°œ ì´ìƒ)
 * - ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸° í…ŒìŠ¤íŠ¸
 * - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
 */
@Service
class UuidProducerService(
    private val kafkaTemplate: KafkaTemplate<String, String>
) {
    
    private val logger = LoggerFactory.getLogger(this::class.java)
    private val messageCount = AtomicLong(0)
    
    companion object {
        const val TOPIC_NAME = "uuid-messages"
        const val BATCH_TOPIC_NAME = "uuid-messages-batch"
        const val HIGH_VOLUME_TOPIC = "uuid-messages-high-volume"
    }
    
    /**
     * ë‹¨ì¼ UUID ë©”ì‹œì§€ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ë°œí–‰
     * 
     * @return ë°œí–‰ëœ ë©”ì‹œì§€ì˜ UUID
     */
    fun sendSingleMessage(): String {
        val uuid = UUID.randomUUID().toString()
        
        return try {
            val result = kafkaTemplate.send(TOPIC_NAME, uuid).get()
            val count = messageCount.incrementAndGet()
            logger.info("ë©”ì‹œì§€ ë°œí–‰ ì„±ê³µ: count={}, partition={}, offset={}, uuid={}", 
                count, result.recordMetadata.partition(), 
                result.recordMetadata.offset(), uuid)
            uuid
        } catch (e: Exception) {
            logger.error("ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: uuid={}", uuid, e)
            throw e
        }
    }
    
    /**
     * ë‹¨ì¼ UUID ë©”ì‹œì§€ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë°œí–‰
     * 
     * @return CompletableFuture<SendResult>
     */
    fun sendMessageAsync(): CompletableFuture<SendResult<String, String>> {
        val uuid = UUID.randomUUID().toString()
        
        return kafkaTemplate.send(TOPIC_NAME, uuid)
            .whenComplete { result, throwable ->
                if (throwable != null) {
                    logger.error("ë¹„ë™ê¸° ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: uuid={}", uuid, throwable)
                } else {
                    val count = messageCount.incrementAndGet()
                    logger.info("ë¹„ë™ê¸° ë©”ì‹œì§€ ë°œí–‰ ì„±ê³µ: count={}, partition={}, offset={}, uuid={}", 
                        count, result.recordMetadata.partition(), 
                        result.recordMetadata.offset(), uuid)
                }
            }
    }
    
    /**
     * ë°°ì¹˜ë¡œ ì—¬ëŸ¬ UUID ë©”ì‹œì§€ë¥¼ ë°œí–‰
     * 
     * @param count ë°œí–‰í•  ë©”ì‹œì§€ ê°œìˆ˜
     * @return ë°œí–‰ëœ UUID ë¦¬ìŠ¤íŠ¸
     */
    fun sendBatchMessages(count: Int): List<String> {
        val uuids = (1..count).map { UUID.randomUUID().toString() }
        
        return uuids.map { uuid ->
            try {
                kafkaTemplate.send(BATCH_TOPIC_NAME, uuid).get()
                uuid
            } catch (e: Exception) {
                logger.error("ë°°ì¹˜ ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: uuid={}", uuid, e)
                throw e
            }
        }
    }
    
    /**
     * ì‹¤ë¬´ ëŒ€ìš©ëŸ‰ ë©”ì‹œì§€ ë°œí–‰ (100ë§Œê°œ ì´ìƒ)
     * 
     * @param count ë°œí–‰í•  ë©”ì‹œì§€ ê°œìˆ˜ (ê¸°ë³¸: 1,000,000ê°œ)
     * @param batchSize ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 10,000ê°œ)
     * @param reportInterval ì„±ëŠ¥ ë¦¬í¬íŠ¸ ê°„ê²© (ê¸°ë³¸: 10,000ê°œë§ˆë‹¤)
     * @param topic ë°œí–‰í•  í† í”½ (ê¸°ë³¸: HIGH_VOLUME_TOPIC)
     */
    fun sendMassiveMessages(count: Long = 1_000_000, batchSize: Int = 10_000, reportInterval: Int = 10_000, topic: String = HIGH_VOLUME_TOPIC) {
        logger.info("ğŸš€ ëŒ€ìš©ëŸ‰ ë©”ì‹œì§€ ë°œí–‰ ì‹œì‘: ì´ {}ê°œ, ë°°ì¹˜ í¬ê¸°: {}, í† í”½: {}", count, batchSize, topic)
        
        val startTime = System.currentTimeMillis()
        val totalBatches = (count / batchSize).toInt()
        
        (0 until totalBatches).forEach { batchIndex ->
            val batchStart = batchIndex * batchSize
            val batchEnd = minOf(batchStart + batchSize.toLong(), count)
            val currentBatchSize = (batchEnd - batchStart).toInt()
            
            // ë°°ì¹˜ ë©”ì‹œì§€ ìƒì„±
            val batch = (0 until currentBatchSize).map { UUID.randomUUID().toString() }
            
            // ë¹„ë™ê¸°ë¡œ ë°°ì¹˜ ë°œí–‰
            val futures = batch.map { uuid ->
                kafkaTemplate.send(topic, uuid)
            }
            
            // ë°°ì¹˜ ì™„ë£Œ ëŒ€ê¸°
            CompletableFuture.allOf(*futures.toTypedArray()).join()
            
            val currentCount = messageCount.addAndGet(currentBatchSize.toLong())
            
            // ì„±ëŠ¥ ë¦¬í¬íŠ¸ (reportIntervalë§ˆë‹¤)
            if (currentCount % reportInterval == 0L) {
                val elapsedTime = System.currentTimeMillis() - startTime
                val rate = currentCount * 1000.0 / elapsedTime
                val progress = (currentCount * 100.0 / count).toInt()
                
                logger.info("ğŸ“Š ë°œí–‰ ì§„í–‰ë¥ : {}/{} ({}%) - ì†ë„: {:.2f} msg/sec - ê²½ê³¼: {}ms", 
                    currentCount, count, progress, rate, elapsedTime)
            }
        }
        
        val endTime = System.currentTimeMillis()
        val duration = endTime - startTime
        val rate = count * 1000.0 / duration
        
        logger.info("âœ… ëŒ€ìš©ëŸ‰ ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ!")
        logger.info("ğŸ“ˆ ìµœì¢… í†µê³„:")
        logger.info("   - ì´ ë°œí–‰ ë©”ì‹œì§€: {}ê°œ", count)
        logger.info("   - ì´ ì†Œìš” ì‹œê°„: {}ms ({}ì´ˆ)", duration, duration / 1000.0)
        logger.info("   - í‰ê·  ë°œí–‰ ì†ë„: {:.2f} msg/sec", rate)
        logger.info("   - ë°°ì¹˜ í¬ê¸°: {}ê°œ", batchSize)
        logger.info("   - ì´ ë°°ì¹˜ ìˆ˜: {}ê°œ", totalBatches)
        logger.info("   - í† í”½: {}", topic)
    }
    
    /**
     * ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
     * 
     * @param totalCount ì´ ë©”ì‹œì§€ ê°œìˆ˜
     * @param batchSizes í…ŒìŠ¤íŠ¸í•  ë°°ì¹˜ í¬ê¸°ë“¤
     */
    fun performanceTestWithDifferentBatchSizes(totalCount: Long = 100_000, batchSizes: List<Int> = listOf(100, 1000, 10000, 50000)) {
        logger.info("ğŸ§ª ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘: ì´ {}ê°œ ë©”ì‹œì§€", totalCount)
        
        batchSizes.forEach { batchSize ->
            logger.info("ğŸ“Š ë°°ì¹˜ í¬ê¸° {}ê°œë¡œ í…ŒìŠ¤íŠ¸ ì‹œì‘...", batchSize)
            
            val startTime = System.currentTimeMillis()
            val totalBatches = (totalCount / batchSize).toInt()
            
            (0 until totalBatches).forEach { batchIndex ->
                val batchStart = batchIndex * batchSize
                val batchEnd = minOf(batchStart + batchSize.toLong(), totalCount)
                val currentBatchSize = (batchEnd - batchStart).toInt()
                
                val batch = (0 until currentBatchSize).map { UUID.randomUUID().toString() }
                val futures = batch.map { uuid ->
                    kafkaTemplate.send(HIGH_VOLUME_TOPIC, uuid)
                }
                
                CompletableFuture.allOf(*futures.toTypedArray()).join()
            }
            
            val endTime = System.currentTimeMillis()
            val duration = endTime - startTime
            val rate = totalCount * 1000.0 / duration
            
            logger.info("ğŸ“ˆ ë°°ì¹˜ í¬ê¸° {}ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:", batchSize)
            logger.info("   - ì†Œìš” ì‹œê°„: {}ms", duration)
            logger.info("   - ì²˜ë¦¬ ì†ë„: {} msg/sec", String.format("%.2f", rate))
            logger.info("   - ë°°ì¹˜ ìˆ˜: {}ê°œ", totalBatches)
            logger.info("   - í‰ê·  ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„: {} ms/batch", String.format("%.2f", duration.toDouble() / totalBatches))
        }
    }
    
    /**
     * ì§€ì†ì ì¸ ë©”ì‹œì§€ ë°œí–‰ (ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ìš©)
     * 
     * @param durationSeconds ì§€ì† ì‹œê°„ (ì´ˆ)
     * @param ratePerSecond ì´ˆë‹¹ ë°œí–‰í•  ë©”ì‹œì§€ ìˆ˜
     */
    fun sendContinuousMessages(durationSeconds: Int = 60, ratePerSecond: Int = 1000) {
        logger.info("ğŸ”„ ì§€ì†ì  ë©”ì‹œì§€ ë°œí–‰ ì‹œì‘: {}ì´ˆê°„ ì´ˆë‹¹ {}ê°œ", durationSeconds, ratePerSecond)
        
        val startTime = System.currentTimeMillis()
        val endTime = startTime + (durationSeconds * 1000L)
        // val intervalMs = 1000L / ratePerSecond  // í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        
        var messageCount = 0L
        
        while (System.currentTimeMillis() < endTime) {
            val batchStart = System.currentTimeMillis()
            
            // ratePerSecondë§Œí¼ ë©”ì‹œì§€ ë°œí–‰
            val futures = (0 until ratePerSecond).map {
                kafkaTemplate.send(HIGH_VOLUME_TOPIC, UUID.randomUUID().toString())
            }
            
            CompletableFuture.allOf(*futures.toTypedArray()).join()
            
            messageCount += ratePerSecond
            
            val batchEnd = System.currentTimeMillis()
            val batchDuration = batchEnd - batchStart
            
            // ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ ëŒ€ê¸°
            if (batchDuration < 1000) {
                Thread.sleep(1000 - batchDuration)
            }
            
            val elapsedSeconds = (System.currentTimeMillis() - startTime) / 1000
            logger.info("ğŸ“Š ì§€ì† ë°œí–‰ ì§„í–‰: {}ì´ˆ ê²½ê³¼, ì´ {}ê°œ ë°œí–‰", elapsedSeconds, messageCount)
        }
        
        val totalDuration = System.currentTimeMillis() - startTime
        val actualRate = messageCount * 1000.0 / totalDuration
        
        logger.info("âœ… ì§€ì†ì  ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ!")
        logger.info("ğŸ“ˆ ìµœì¢… í†µê³„:")
        logger.info("   - ì´ ë°œí–‰ ë©”ì‹œì§€: {}ê°œ", messageCount)
        logger.info("   - ì´ ì†Œìš” ì‹œê°„: {}ms", totalDuration)
        logger.info("   - ì‹¤ì œ ë°œí–‰ ì†ë„: {} msg/sec", String.format("%.2f", actualRate))
        logger.info("   - ëª©í‘œ ë°œí–‰ ì†ë„: {} msg/sec", ratePerSecond)
    }
    
    /**
     * í˜„ì¬ ë°œí–‰ í†µê³„ ì¡°íšŒ
     */
    fun getStatistics(): Map<String, Any> {
        return mapOf(
            "totalMessagesSent" to messageCount.get(),
            "topics" to listOf(TOPIC_NAME, BATCH_TOPIC_NAME, HIGH_VOLUME_TOPIC)
        )
    }
} 